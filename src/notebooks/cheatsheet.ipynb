{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataframe.csv')\n",
    "df.to_csv('submission.csv', index=False, header=True)\n",
    "\n",
    "df.select_dtypes(object)\n",
    "df.select_dtypes(np.number)\n",
    "\n",
    "df = df.map(dict)\n",
    "\n",
    "df.column = df.column.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 1\n",
    "y = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42)\n",
    "\n",
    "data = pd.concat([X_train, X_test], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_X = np.log(X)\n",
    "log1p_X = np.log1p(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "def my_function(df):\n",
    "    df['columna1'] = SimpleImputer(strategy='mean')\n",
    "    df['columna2'] = SimpleImputer(strategy='median')\n",
    "    return df\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit_transform(X)\n",
    "\n",
    "# METODO 2\n",
    "X_dummie = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "X_scal = StandardScaler().fit_transform(X)\n",
    "X_scal = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree = 3)\n",
    "poly.fit(X)\n",
    "X_poly = poly.transform(X)\n",
    "X_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "X_kbest = SelectKBest(k=5).fit_transform(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "skew_df = pd.DataFrame(df.select_dtypes(np.number).columns, columns=['Feature'])\n",
    "skew_df['Skew'] = skew_df['Feature'].apply(lambda feature: skew(df[feature]))\n",
    "skew_df['Absolute Skew'] = skew_df['Skew'].apply(abs)\n",
    "skew_df['Skewed'] = skew_df['Absolute Skew'].apply(lambda x: True if x >= 0.5 else False)\n",
    "skew_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "lm = LinearRegression()\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "svm_poly_reg = SVR(kernel=\"poly\", degree=2, C=100, epsilon=0.1, gamma=\"scale\")\n",
    "from sklearn.svm import LinearSVR\n",
    "svm_reg = LinearSVR(epsilon=1.5, random_state=42)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rnd_reg = RandomForestRegressor(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ada_reg = AdaBoostRegressor(n_estimators=200, random_state=42)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0, random_state=42)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "xgb_reg = XGBRegressor(random_state=42)\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "cat_reg = CatBoostRegressor(verbose=0)\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "lgb_reg = LGBMRegressor()\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "estimators = [('lr', lm), ('rf', tree_reg), ('svc', svm_reg)]\n",
    "voting_clf = VotingRegressor(estimators=estimators)\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge, HuberRegressor, OrthogonalMatchingPursuit\n",
    "\n",
    "lm.fit(X_train, y_train)\n",
    "y_pred = lm.predict(X_test)\n",
    "\n",
    "sns.scatterplot(y_test, y_pred)\n",
    "print(lm.intercept_, lm.coef_)\n",
    "print('Score:', lm.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_clf = LogisticRegression()\n",
    "log_clf.classes_\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.classes_\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svm_clf = SVC(kernel='linear', C = float(0.5))\n",
    "svm_clf =  SVC(kernel = \"poly\", degree=3, coef0=1, C=5)\n",
    "from sklearn.svm import LinearSVC\n",
    "Linear_svc = LinearSVC(C = 1, loss='hinge', random_state=42)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "estimator = DecisionTreeClassifier(max_depth=1)\n",
    "ada_clf = AdaBoostClassifier(base_estimator = estimator, n_estimators=200, learning_rate=0.5, random_state=42)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbct = GradientBoostingClassifier(max_depth=2, n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "from xgboost import XGBRFClassifier\n",
    "xgb_clas = XGBRFClassifier(random_state=42)\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "cat_clas = CatBoostClassifier(verbose=0)\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "lgb_clas = LGBMClassifier()\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "estimators = [('lr', log_clf), ('rf', tree_clf), ('svc', svm_clf)]\n",
    "voting_clf = VotingClassifier(estimators=estimators, voting='hard')\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "estimator = tree_clf\n",
    "bag_clf = BaggingClassifier(base_estimator = estimator,\n",
    "    n_estimators=500, # Cantidad de árboles\n",
    "    max_samples=100, # Muestras utilizadas en bootsrapping\n",
    "    bootstrap=True, # Usamos bootsrapping\n",
    "    max_features = 3 # Features que utiliza en el bootsrapping. Cuanto más bajo, mejor generalizará y menos overfitting\n",
    "    random_state=42)\n",
    "\n",
    "log_clf.fit(X, y)\n",
    "y_pred = log_clf.predict(X)\n",
    "pred_proba = log_clf.predict_proba(X)\n",
    "log_clf.score(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "per_clf = Perceptron(random_state=1)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(max_iter=500,activation='tanh',hidden_layer_sizes = (150, 150, 150),random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,activation='relu'))\n",
    "model.add(keras.layers.Dense(units = 100,activation='relu'))\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,activation='softmax'))\n",
    "\n",
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "model = keras.models.Sequential(capas)\n",
    "\n",
    "#Regression\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu', input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = \"sgd\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer = \"adam\", # \"adagrad\", \"adam\"\n",
    "    loss = \"sparse_categorical_crossentropy\", # binary_crossentropy\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "model.evaluate(X_test, y_test)\n",
    "model.save(\"my_keras_model.h5\")\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_split = 0.1\n",
    ")\n",
    "\n",
    "history.params\n",
    "history.epoch\n",
    "history.history\n",
    "history.history.keys()\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"catboost\": CatBoostRegressor(verbose=0),\n",
    "    \"br\": BayesianRidge(),\n",
    "    \"lightgbm\": LGBMRegressor(),\n",
    "    \"ridge\": Ridge(),\n",
    "    \"omp\": OrthogonalMatchingPursuit()\n",
    "}\n",
    "final_predictions = (\n",
    "    0.4 * np.exp(models['catboost'].predict(X)) +\n",
    "    0.2 * np.exp(models['br'].predict(X)) +\n",
    "    0.2 * np.exp(models['lightgbm'].predict(X)) +\n",
    "    0.1 * np.exp(models['ridge'].predict(X)) +\n",
    "    0.1 * np.exp(models['omp'].predict(X))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Ridge, Lasso\n",
    "ridgeR = Ridge(alpha = 9)\n",
    "ridgeR.fit(X_train, y_train)\n",
    "lassoR = Lasso(alpha=42)\n",
    "lassoR.fit(X_train, y_train)\n",
    "elastic_net = ElasticNet(alpha = 1, l1_ratio = 0.5)\n",
    "elastic_net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(lm.coef_, X.columns, columns=['coefficient']).sort_values('coefficient', ascending=False)\n",
    "plt.barh(features.index, features.coefficient);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_error, r2_score\n",
    "print('MAE:', mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('MAPE:', np.sqrt(mean_squared_error(y_test, y_pred))/y.mean())\n",
    "print('R2_Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "c_matrix = confusion_matrix(y_test, y_pred)\n",
    "multilabel_confusion_matrix(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold, RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=None, shuffle=True)\n",
    "scores = cross_val_score (X, y, estimator=knn, cv=cv, scoring='accuracy')\n",
    "\n",
    "params = {'n_neighbors':range(1, 40)}\n",
    "clf = GridSearchCV(estimator = knn, param_grid = params, scoring='accuracy', cv=cv)\n",
    "\n",
    "clf.best_params_\n",
    "clf.best_estimator_\n",
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Productivization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'my_model.pkl'\n",
    "with open(filename, 'wb') as archivo_salida:\n",
    "    pickle.dump(lm, archivo_salida)\n",
    "with open(filename, 'rb') as archivo_entrada:\n",
    "    modelo_importado = pickle.load(archivo_entrada)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "reg_log = Pipeline(steps = [\n",
    "    (\"imputer\", SimpleImputer()),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"selectkbest\", SelectKBest()),\n",
    "    (\"reglog\", LogisticRegression())\n",
    "])\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(StandardScaler(), PCA(n_components=4))\n",
    "pipe.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNSUPERVISED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(estimator=svm_clf, n_features_to_select=10, step=1)\n",
    "rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "x_data_varth = VarianceThreshold(.9).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "data = pca.fit_transform(X)\n",
    "\n",
    "pca.n_components_\n",
    "pca.explained_variance_ratio_\n",
    "\n",
    "# Reduce the image dimensions to  2 so that we can visualize the dataset using a Scatterplot.\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.figure(figsize = (10,6))\n",
    "c_map = plt.cm.get_cmap('jet', 10)\n",
    "plt.scatter(data[:, 0], data[:, 1], s = 15, cmap = c_map , c = y)\n",
    "plt.colorbar()\n",
    "plt.xlabel('PC-1') , plt.ylabel('PC-2')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=3, random_state=101)\n",
    "y_pred = kmeans.fit_predict(X)\n",
    "kmeans.transform(X)\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "minibatch_kmeans = MiniBatchKMeans(n_clusters=5, random_state=42)\n",
    "minibatch_kmeans.fit(X)\n",
    "\n",
    "kmeans.score(X)\n",
    "kmeans.inertia_\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pycaret\n",
    "from pycaret.regression import setup, compare_models\n",
    "# from pycaret.classification import setup, compare_models\n",
    "setup(data=pd.concat([X, y], axis=1), target='target')\n",
    "compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import os\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    os.listdir()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('the_bridge')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bf612fd9f670b4cbe581c743168f3e65e97abe2c4dc839c108fa6dc9b2daabc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
